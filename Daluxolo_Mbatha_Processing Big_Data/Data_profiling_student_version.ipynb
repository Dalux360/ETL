{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Big Data - Data profiling\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "## Honour Code\n",
    "I {**Daluxolo**, **Mbatha**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "    Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "## Context\n",
    "\n",
    "Having completed the first step - data ingestion, the data now needs to be thoroughly prepared so that it is readable, reliable and robust. As the Data Engineer in the team, this will be your responsibility. The Data Scientists are looking to you to clean this data so that model development and deployment become seamless when the data is used in a production environment. Having completed your Data Engineering course recently, your manager Gnissecorp Atadgid, asks you to create data summaries and perform checks using the six dimensions of data quality.\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/raw/master/data_engineering/transform/predict/DataQuality.jpg\"\n",
    "     alt=\"Data Quality\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=100%/>\n",
    "     <p><em>Figure 1. Six dimensions of data quality</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "Below we import the libraries required to complete this section of the predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import Window\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we need a `SparkContext` and `SparkSession` to interface with Spark.\n",
    "We will mostly be using the `SparkContext` to interact with RDDs \n",
    "and the `SparkSession` to interface with Python objects.\n",
    "\n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    ">Initialise a new **Spark Context** and **Session** that you will use to interface with Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Write your code here.\n",
    "spark = SparkSession.builder\\\n",
    "  .config(\"spark.sql.shuffle.partitions\", 5)\\\n",
    "  .config(\"spark.executor.memory\", \"8g\")\\\n",
    "  .master(\"local[*]\")\\\n",
    "  .appName(\"Predict\")\\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet files\n",
    "In the previous section of the predict, you generated parquet files to your local directory. You will be making use of these files to continue with this section of the predict. Please make sure that your parquet files are specifically for the year **1962**. Any other year used outside of **1962** will produce incorrect answers and have a negative impact on your overall predict mark.\n",
    "\n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Read the parquet files stored in your directory for the year **1962** into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-02-19</td>\n",
       "      <td>5.839290</td>\n",
       "      <td>5.907375</td>\n",
       "      <td>5.839290</td>\n",
       "      <td>5.863320</td>\n",
       "      <td>1.386329</td>\n",
       "      <td>29900.0</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-02-19</td>\n",
       "      <td>5.481634</td>\n",
       "      <td>5.528486</td>\n",
       "      <td>5.481634</td>\n",
       "      <td>5.516773</td>\n",
       "      <td>1.280453</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>ARNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-02-19</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.915638</td>\n",
       "      <td>0.899177</td>\n",
       "      <td>0.903292</td>\n",
       "      <td>0.161415</td>\n",
       "      <td>619400.0</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-02-19</td>\n",
       "      <td>1.677083</td>\n",
       "      <td>1.692708</td>\n",
       "      <td>1.661458</td>\n",
       "      <td>1.677083</td>\n",
       "      <td>0.144059</td>\n",
       "      <td>170400.0</td>\n",
       "      <td>CAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-02-19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.578869</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.549107</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>273600.0</td>\n",
       "      <td>CVX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>1962-12-07</td>\n",
       "      <td>0.223307</td>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>921600.0</td>\n",
       "      <td>KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>1962-12-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131727</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>691200.0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>1962-12-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>115.858948</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>NAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>1962-12-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.158203</td>\n",
       "      <td>1.144531</td>\n",
       "      <td>1.154297</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>198400.0</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>1962-12-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.820312</td>\n",
       "      <td>1.785156</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>1846400.0</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5106 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      open        high        low       close   adj_close  \\\n",
       "0     1962-02-19  5.839290    5.907375   5.839290    5.863320    1.386329   \n",
       "1     1962-02-19  5.481634    5.528486   5.481634    5.516773    1.280453   \n",
       "2     1962-02-19  0.907407    0.915638   0.899177    0.903292    0.161415   \n",
       "3     1962-02-19  1.677083    1.692708   1.661458    1.677083    0.144059   \n",
       "4     1962-02-19  0.000000    3.578869  20.000000    3.549107    0.056501   \n",
       "...          ...       ...         ...        ...         ...         ...   \n",
       "5101  1962-12-07  0.223307    0.223958   0.222656    0.223958    0.003711   \n",
       "5102  1962-12-07  0.000000    0.131727   0.130859    0.130859    0.000166   \n",
       "5103  1962-12-07  0.000000  251.875000        NaN  250.000000  115.858948   \n",
       "5104  1962-12-07  0.000000    1.158203   1.144531    1.154297    0.011131   \n",
       "5105  1962-12-07  0.000000    1.820312   1.785156    1.812500    0.016743   \n",
       "\n",
       "         volume stock  \n",
       "0       29900.0    AA  \n",
       "1       32000.0  ARNC  \n",
       "2      619400.0    BA  \n",
       "3      170400.0   CAT  \n",
       "4      273600.0   CVX  \n",
       "...         ...   ...  \n",
       "5101   921600.0    KO  \n",
       "5102   691200.0    MO  \n",
       "5103     1400.0   NAV  \n",
       "5104   198400.0    PG  \n",
       "5105  1846400.0   XOM  \n",
       "\n",
       "[5106 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "stocks = spark.read.parquet('/Users/daluxolombatha/Desktop/daluxolos_predict/*')\n",
    "stocks.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata \n",
    "\n",
    "Metadata is data containing additional information about the data itself. In the cloud storage, there is a metadata file called [`symbols_valid_meta.csv`](https://processing-big-data-predict-stocks-data.s3.eu-west-1.amazonaws.com/symbols_valid_meta.csv) that is collocated with the stock market data. You will need to download this to use when performing your data quality checks.\n",
    "\n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Download the metadata from the S3 bucket and read it into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------------------+----------------+---------------+---+--------------+----------+----------------+----------+-------------+----------+\n",
      "|Nasdaq Traded|Symbol|       Security Name|Listing Exchange|Market Category|ETF|Round Lot Size|Test Issue|Financial Status|CQS Symbol|NASDAQ Symbol|NextShares|\n",
      "+-------------+------+--------------------+----------------+---------------+---+--------------+----------+----------------+----------+-------------+----------+\n",
      "|            Y|     A|Agilent Technolog...|               N|               |  N|         100.0|         N|            null|         A|            A|         N|\n",
      "|            Y|    AA|Alcoa Corporation...|               N|               |  N|         100.0|         N|            null|        AA|           AA|         N|\n",
      "|            Y|  AAAU|Perth Mint Physic...|               P|               |  Y|         100.0|         N|            null|      AAAU|         AAAU|         N|\n",
      "|            Y|  AACG|ATA Creativity Gl...|               Q|              G|  N|         100.0|         N|               N|      null|         AACG|         N|\n",
      "|            Y|  AADR|AdvisorShares Dor...|               P|               |  Y|         100.0|         N|            null|      AADR|         AADR|         N|\n",
      "|            Y|   AAL|American Airlines...|               Q|              Q|  N|         100.0|         N|               N|      null|          AAL|         N|\n",
      "|            Y|  AAMC|Altisource Asset ...|               A|               |  N|         100.0|         N|            null|      AAMC|         AAMC|         N|\n",
      "|            Y|  AAME|Atlantic American...|               Q|              G|  N|         100.0|         N|               N|      null|         AAME|         N|\n",
      "|            Y|   AAN|Aaron's, Inc. Com...|               N|               |  N|         100.0|         N|            null|       AAN|          AAN|         N|\n",
      "|            Y|  AAOI|Applied Optoelect...|               Q|              G|  N|         100.0|         N|               N|      null|         AAOI|         N|\n",
      "|            Y|  AAON|AAON, Inc. - Comm...|               Q|              Q|  N|         100.0|         N|               N|      null|         AAON|         N|\n",
      "|            Y|   AAP|Advance Auto Part...|               N|               |  N|         100.0|         N|            null|       AAP|          AAP|         N|\n",
      "|            Y|  AAPL|Apple Inc. - Comm...|               Q|              Q|  N|         100.0|         N|               N|      null|         AAPL|         N|\n",
      "|            Y|   AAT|American Assets T...|               N|               |  N|         100.0|         N|            null|       AAT|          AAT|         N|\n",
      "|            Y|   AAU|Almaden Minerals,...|               A|               |  N|         100.0|         N|            null|       AAU|          AAU|         N|\n",
      "|            Y|  AAWW|Atlas Air Worldwi...|               Q|              Q|  N|         100.0|         N|               N|      null|         AAWW|         N|\n",
      "|            Y|  AAXJ|iShares MSCI All ...|               Q|              G|  Y|         100.0|         N|               N|      null|         AAXJ|         N|\n",
      "|            Y|  AAXN|Axon Enterprise, ...|               Q|              Q|  N|         100.0|         N|               N|      null|         AAXN|         N|\n",
      "|            Y|    AB|AllianceBernstein...|               N|               |  N|         100.0|         N|            null|        AB|           AB|         N|\n",
      "|            Y|   ABB|ABB Ltd Common Stock|               N|               |  N|         100.0|         N|            null|       ABB|          ABB|         N|\n",
      "+-------------+------+--------------------+----------------+---------------+---+--------------+----------+----------------+----------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "metadata_raw = spark.read.csv('/Users/daluxolombatha/Desktop/last_dance/symbols_valid_meta.csv', header=True)\n",
    "metadata_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Nasdaq Traded: string (nullable = true)\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Security Name: string (nullable = true)\n",
      " |-- Listing Exchange: string (nullable = true)\n",
      " |-- Market Category: string (nullable = true)\n",
      " |-- ETF: string (nullable = true)\n",
      " |-- Round Lot Size: string (nullable = true)\n",
      " |-- Test Issue: string (nullable = true)\n",
      " |-- Financial Status: string (nullable = true)\n",
      " |-- CQS Symbol: string (nullable = true)\n",
      " |-- NASDAQ Symbol: string (nullable = true)\n",
      " |-- NextShares: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, the schema looks spot on, with most pf the values being strings. I do however believe that the Round Lot Size column will need to be converted into a float type. converting the colums below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Nasdaq Traded: string (nullable = true)\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Security Name: string (nullable = true)\n",
      " |-- Listing Exchange: string (nullable = true)\n",
      " |-- Market Category: string (nullable = true)\n",
      " |-- ETF: string (nullable = true)\n",
      " |-- Round Lot Size: float (nullable = true)\n",
      " |-- Test Issue: string (nullable = true)\n",
      " |-- Financial Status: string (nullable = true)\n",
      " |-- CQS Symbol: double (nullable = true)\n",
      " |-- NASDAQ Symbol: string (nullable = true)\n",
      " |-- NextShares: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " schema = StructType([ \\\n",
    "    StructField(\"Nasdaq Traded\", StringType(),True), \\\n",
    "    StructField(\"Symbol\", StringType(),True), \\\n",
    "    StructField(\"Security Name\", StringType(),True), \\\n",
    "    StructField(\"Listing Exchange\", StringType(),True), \\\n",
    "    StructField(\"Market Category\", StringType(), True), \\\n",
    "    StructField(\"ETF\", StringType(), True), \\\n",
    "    StructField(\"Round Lot Size\", FloatType(), True), \\\n",
    "    StructField(\"Test Issue\", StringType(), True), \\\n",
    "    StructField(\"Financial Status\", StringType(), True), \\\n",
    "    StructField(\"CQS Symbol\", DoubleType(), True), \\\n",
    "    StructField(\"NASDAQ Symbol\", StringType(), True), \\\n",
    "    StructField(\"NextShares\", StringType(), True)\n",
    "  ])\n",
    "    \n",
    "    \n",
    "metadata = \\\n",
    "spark.read.csv('/Users/daluxolombatha/Desktop/last_dance/symbols_valid_meta.csv',\\\n",
    "               header=True,schema= schema)\n",
    "\n",
    "metadata.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, the schema has been read in properly. Now the fum begins. From the onset, it looks there are a bunch of missing values here that will will need addrssing in the futer. Just noting this for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Accuracy\n",
    "Data accuracy is the degree to which data correctly describes a \"real world\" object or event.\n",
    "\n",
    "It is important to do checks to determine the basic integrity of the dataset; do the values fall within expected ranges?\n",
    "\n",
    "Most of the possible errors relating to data accuracy can occur at collection time. In our case, it is not possible to test the collection time accuracy, so we have to infer from ranges and summary statistics. Here you need to look closely at each field to see if its values make sense, with no strange surprises.\n",
    "\n",
    "In assessing accuracy, it is important to look into precision as well. Do you need seven decimals, or will one or two suffice?\n",
    "\n",
    "- **Measured by**: The degree to which the data mirrors the characteristics of the real-world object or objects it represents;\n",
    "- **Units**: The percentage of data entries that pass the data accuracy rules;\n",
    "- **Related to**: Validity, Uniqueness, Consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Generate summary statistics to explore your data. Make sure you understand the ranges, means, extremums, and deviations found in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>5106</td>\n",
       "      <td>5106</td>\n",
       "      <td>5064</td>\n",
       "      <td>5106</td>\n",
       "      <td>5085</td>\n",
       "      <td>5085</td>\n",
       "      <td>5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1.0904873526012002</td>\n",
       "      <td>16.757624946793637</td>\n",
       "      <td>15.728619917198033</td>\n",
       "      <td>16.64199179044607</td>\n",
       "      <td>5.9866425135353065</td>\n",
       "      <td>540930.2458210423</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>2.3644535253049104</td>\n",
       "      <td>53.91407348193547</td>\n",
       "      <td>51.32292289814397</td>\n",
       "      <td>53.54677139900803</td>\n",
       "      <td>24.646370547153204</td>\n",
       "      <td>864596.2440525504</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052377883</td>\n",
       "      <td>0.053624976</td>\n",
       "      <td>4.0381454E-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2454427</td>\n",
       "      <td>0.24348958</td>\n",
       "      <td>0.24739583</td>\n",
       "      <td>0.006592116</td>\n",
       "      <td>38400.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8046875</td>\n",
       "      <td>1.7851562</td>\n",
       "      <td>1.8007812</td>\n",
       "      <td>0.12449309</td>\n",
       "      <td>177600.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75%</td>\n",
       "      <td>0.69547325</td>\n",
       "      <td>6.903353</td>\n",
       "      <td>6.7916665</td>\n",
       "      <td>6.8333335</td>\n",
       "      <td>0.7141595</td>\n",
       "      <td>734400.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max</td>\n",
       "      <td>20.0</td>\n",
       "      <td>287.5</td>\n",
       "      <td>282.5</td>\n",
       "      <td>285.0</td>\n",
       "      <td>127.45936</td>\n",
       "      <td>1.95456E7</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                open                high                 low  \\\n",
       "0   count                5106                5106                5064   \n",
       "1    mean  1.0904873526012002  16.757624946793637  15.728619917198033   \n",
       "2  stddev  2.3644535253049104   53.91407348193547   51.32292289814397   \n",
       "3     min                 0.0                 0.0         0.052377883   \n",
       "4     25%                 0.0           0.2454427          0.24348958   \n",
       "5     50%                 0.0           1.8046875           1.7851562   \n",
       "6     75%          0.69547325            6.903353           6.7916665   \n",
       "7     max                20.0               287.5               282.5   \n",
       "\n",
       "               close           adj_close             volume stock  \n",
       "0               5106                5085               5085  5106  \n",
       "1  16.64199179044607  5.9866425135353065  540930.2458210423  None  \n",
       "2  53.54677139900803  24.646370547153204  864596.2440525504  None  \n",
       "3        0.053624976        4.0381454E-7                0.0    AA  \n",
       "4         0.24739583         0.006592116            38400.0  None  \n",
       "5          1.8007812          0.12449309           177600.0  None  \n",
       "6          6.8333335           0.7141595           734400.0  None  \n",
       "7              285.0           127.45936          1.95456E7   XOM  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "stocks.summary().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the summary statistics, we can see that the mean open value is around **1.09**, mean high is at **16.75**, mean low is **15.72**, mean close is at **16.64** adjusted close is **5.99** and the volume is **540930.25**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the medians of each column, the low and close values seem to moving equally here, not too sure if that menas anything but they're tending to look like mirror images of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Generate histograms for the six numerical attributes found in the data to understand the distribution of values.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'open'}>,\n",
       "        <AxesSubplot:title={'center':'high'}>],\n",
       "       [<AxesSubplot:title={'center':'low'}>,\n",
       "        <AxesSubplot:title={'center':'close'}>],\n",
       "       [<AxesSubplot:title={'center':'adj_close'}>,\n",
       "        <AxesSubplot:title={'center':'volume'}>]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "stocks.toPandas().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these histograms look like they have a normal distribution, as a matter of fact all of them look like threy're skewed to the right, which indidcates that the mode is the highest point in all these distributions. Let's take a look athe diffeent modes for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>5106</td>\n",
       "      <td>5106</td>\n",
       "      <td>5064</td>\n",
       "      <td>5106</td>\n",
       "      <td>5085</td>\n",
       "      <td>5085</td>\n",
       "      <td>5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1.0904873526012002</td>\n",
       "      <td>16.757624946793637</td>\n",
       "      <td>15.728619917198033</td>\n",
       "      <td>16.64199179044607</td>\n",
       "      <td>5.9866425135353065</td>\n",
       "      <td>540930.2458210423</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>2.3644535253049104</td>\n",
       "      <td>53.91407348193547</td>\n",
       "      <td>51.32292289814397</td>\n",
       "      <td>53.54677139900803</td>\n",
       "      <td>24.646370547153204</td>\n",
       "      <td>864596.2440525504</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052377883</td>\n",
       "      <td>0.053624976</td>\n",
       "      <td>4.0381454E-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>20.0</td>\n",
       "      <td>287.5</td>\n",
       "      <td>282.5</td>\n",
       "      <td>285.0</td>\n",
       "      <td>127.45936</td>\n",
       "      <td>1.95456E7</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                open                high                 low  \\\n",
       "0   count                5106                5106                5064   \n",
       "1    mean  1.0904873526012002  16.757624946793637  15.728619917198033   \n",
       "2  stddev  2.3644535253049104   53.91407348193547   51.32292289814397   \n",
       "3     min                 0.0                 0.0         0.052377883   \n",
       "4     max                20.0               287.5               282.5   \n",
       "\n",
       "               close           adj_close             volume stock  \n",
       "0               5106                5085               5085  5106  \n",
       "1  16.64199179044607  5.9866425135353065  540930.2458210423  None  \n",
       "2  53.54677139900803  24.646370547153204  864596.2440525504  None  \n",
       "3        0.053624976        4.0381454E-7                0.0    AA  \n",
       "4              285.0           127.45936          1.95456E7   XOM  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, None, 29.5, None]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.describe().toPandas()\n",
    "modes = stocks['open','high','low','close','adj_close']\n",
    "[modes.groupby(i).count().orderBy(\"count\", ascending=False).first()[0] for i in modes.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a list of the modes of the all the columns. The low and the close have the same mode, thats very intersting. Also makes sense for the modes to be the highest values since the Distributions are right skewed, it look like HPQ (HP) os a very popular stock, appearing more than the 251 times all the other stocks seem to be appearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[0.2473958283662796]\n",
      "[0.2486979216337204]\n",
      "[0.2578125]\n",
      "[0.006715100724250078]\n",
      "[42000.0]\n"
     ]
    }
   ],
   "source": [
    "print(stocks.approxQuantile('open', [0.5], 0.25)) #-- gives the medain of each column\n",
    "print(stocks.approxQuantile('high', [0.5], 0.25))\n",
    "print(stocks.approxQuantile('low', [0.5], 0.25))\n",
    "print(stocks.approxQuantile('close', [0.5], 0.25))\n",
    "print(stocks.approxQuantile('adj_close', [0.5], 0.25))\n",
    "print(stocks.approxQuantile('volume', [0.5], 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Investigate the **open** column to identify stocks that have open values greater than 2, and note any anomalies that you find in the data.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+--------+---------+---------+--------+-----+\n",
      "|      date|    open|     high|     low|    close|adj_close|  volume|stock|\n",
      "+----------+--------+---------+--------+---------+---------+--------+-----+\n",
      "|1962-02-19| 5.83929| 5.907375| 5.83929|  5.86332|1.3863293| 29900.0|   AA|\n",
      "|1962-02-19|5.481634| 5.528486|5.481634|5.5167727|1.2804527| 32000.0| ARNC|\n",
      "|1962-02-19|    7.26|7.2933335|7.173333|7.1866665|0.5825691|280000.0|  IBM|\n",
      "|1962-02-14| 5.83929|  5.83929|5.747175|  5.80725|1.3730713| 56500.0|   AA|\n",
      "|1962-02-14|5.481634| 5.481634|5.399644|5.4347825|1.2614225| 60400.0| ARNC|\n",
      "+----------+--------+---------+--------+---------+---------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "stocks.where(~F.col('open').between(0, 2)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|stock|\n",
      "+-----+\n",
      "|   AA|\n",
      "|  IBM|\n",
      "| ARNC|\n",
      "|   PG|\n",
      "|ARNCA|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks.createOrReplaceTempView('tbl')\n",
    "\n",
    "spark.sql(\"\"\"SELECT distinct(stock)\n",
    "             FROM tbl\n",
    "             WHERE open >2 \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 753 instances where the open price is higher than 2 dollars, ant this is because of three stocks responsible for this are AA, ARNC and IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| AA|\n",
      "+---+\n",
      "|252|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT count(stock) as AA\n",
    "             FROM tbl\n",
    "             WHERE open >2 and stock = 'AA'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|IBM|\n",
      "+---+\n",
      "|252|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT count(stock) as IBM\n",
    "             FROM tbl\n",
    "             WHERE open >2 and stock = 'IBM'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|ARNC|\n",
      "+----+\n",
      "| 231|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT count(stock) as ARNC\n",
    "             FROM tbl\n",
    "             WHERE open >2 and stock = 'ARNC'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------+----------+-----------+------------+---------+-----+\n",
      "|      date|       open|       high|       low|      close|   adj_close|   volume|stock|\n",
      "+----------+-----------+-----------+----------+-----------+------------+---------+-----+\n",
      "|1962-02-19|  0.9074074| 0.91563785|0.89917696|  0.9032922|  0.16141544| 619400.0|   BA|\n",
      "|1962-02-19|  1.6770834|  1.6927084| 1.6614584|  1.6770834|   0.1440587| 170400.0|  CAT|\n",
      "|1962-02-19|        0.0|   3.578869|      20.0|   3.549107| 0.056501225| 273600.0|  CVX|\n",
      "|1962-02-19|0.099767394|0.099767394|0.09820853| 0.09820853| 0.037543412| 817400.0|  DIS|\n",
      "|1962-02-19|        0.0|    29.9375|     29.75|    29.9375|  0.49964145|   1600.0|  DTE|\n",
      "|1962-02-19|        0.0|   9.921875|  9.890625|   9.921875|  0.22499175|   8800.0|   ED|\n",
      "|1962-02-19|        0.0|  7.0833335| 7.0208335|  7.0208335|  0.91296524|  20400.0|   FL|\n",
      "|1962-02-19| 0.77373797|   0.777494|0.76372194|   0.767478|0.0018262818|1557500.0|   GE|\n",
      "|1962-02-19|        0.0|    10.9375|     10.75|    10.9375|   1.9131781|  22800.0|   GT|\n",
      "|1962-02-19| 0.11264618| 0.11397664|0.11264618|0.113089666| 0.006272347| 591800.0|  HPQ|\n",
      "+----------+-----------+-----------+----------+-----------+------------+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT *\n",
    "             FROM tbl\n",
    "             where  open <4 \"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM is doing a very good job at skewing the data. Itopens up very high consistantly. It looks like for a normal distribution, we need to look at stocks with an opening between 0 - 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the open values that are higher than 2, we only see 3 rows in total. Looks they all opened above $6.00 but that IBM stock looks really off - definately an outlier that we could and should remove. AA and ARNC my also need to be removed as they may be skewing the results looking at the respective column means, meadians and modes these columns are nowhere near these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 📔️**Notes** 📔️\n",
    "\n",
    " *Use this cell to note down any potential findings.*\n",
    "\n",
    " 1. Looking at the summary statistics, we can see that the mean open value is around **1.09**, mean high is at **16.75**, mean low is **15.72**, mean close is at **16.64** adjusted close is **5.99** and the volume is **540930.25**\n",
    " \n",
    " 2. The mode for the ope column is 0.0 and this alsommakes sense becaue most stoks open up at $0.00 \n",
    " 3. None of these colunms look like they have a normal distribution oand the open column is no different. As a matter of fact, all of them look like threy're skewed to the right, which indidcates that the mode is the highest point in all these distributions.\n",
    " \n",
    "4. Looking at the open values that are higher than 2, we aonly see 3 rows in total. Looks they all opened above $6.00 but that IBM stock looks really off - definately an outlier that we could and should remove. AA and ARNC my also need to be removed as they may be skewing the results looking at the respective column means, meadians and modes these columns are nowhere near these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Investigate **high**, **low**, **close**, and **adj_close** to determine if any stocks may be deviating from the normal ranges of the data set. Note down the stock(s) that you come across.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>5106</td>\n",
       "      <td>5064</td>\n",
       "      <td>5106</td>\n",
       "      <td>5085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>16.757624946793637</td>\n",
       "      <td>15.728619917198033</td>\n",
       "      <td>16.64199179044607</td>\n",
       "      <td>5.9866425135353065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>53.91407348193547</td>\n",
       "      <td>51.32292289814397</td>\n",
       "      <td>53.54677139900803</td>\n",
       "      <td>24.646370547153204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052377883</td>\n",
       "      <td>0.053624976</td>\n",
       "      <td>4.0381454E-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>287.5</td>\n",
       "      <td>282.5</td>\n",
       "      <td>285.0</td>\n",
       "      <td>127.45936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                high                 low              close  \\\n",
       "0   count                5106                5064               5106   \n",
       "1    mean  16.757624946793637  15.728619917198033  16.64199179044607   \n",
       "2  stddev   53.91407348193547   51.32292289814397  53.54677139900803   \n",
       "3     min                 0.0         0.052377883        0.053624976   \n",
       "4     max               287.5               282.5              285.0   \n",
       "\n",
       "            adj_close  \n",
       "0                5085  \n",
       "1  5.9866425135353065  \n",
       "2  24.646370547153204  \n",
       "3        4.0381454E-7  \n",
       "4           127.45936  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "stocks.describe(['high','low','close','adj_close']).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_high = 16.757624946793637\n",
    "median_high = 0.2473958283662796\n",
    "mode_high = 0\n",
    "\n",
    "mean_low = 15.728619917198033\n",
    "median_low = 0.2486979216337204\n",
    "mode_low = 0\n",
    "\n",
    "mean_close = 16.641991790446072\n",
    "median_close = 0.2578125\n",
    "mode_close = None\n",
    "\n",
    "mean_adj_close = 5.9866425135353065\n",
    "median_adj_close = 42000.0\n",
    "mode_adj_close = 29.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-------+-----+\n",
      "|open|   high|    low|  close|stock|\n",
      "+----+-------+-------+-------+-----+\n",
      "| 0.0|29.9375|  29.75|29.9375|  DTE|\n",
      "| 0.0|  280.0|276.875|279.375|  NAV|\n",
      "| 0.0|30.1875|29.6875| 29.875|  DTE|\n",
      "| 0.0|276.875|273.125| 273.75|  NAV|\n",
      "| 0.0|30.3125| 29.875|  30.25|  DTE|\n",
      "+----+-------+-------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks.createOrReplaceTempView('explore')\n",
    "\n",
    "spark.sql(\"\"\"SELECT open,high,low,close,stock\n",
    "            FROM explore\n",
    "            WHERE high > 16.757624946793637\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+-------+-------+----------+------+-----+\n",
      "|      date|open|   high|    low|  close| adj_close|volume|stock|\n",
      "+----------+----+-------+-------+-------+----------+------+-----+\n",
      "|1962-02-19| 0.0|29.9375|  29.75|29.9375|0.49964145|1600.0|  DTE|\n",
      "|1962-02-19| 0.0|  280.0|276.875|279.375| 124.94374| 600.0|  NAV|\n",
      "|1962-02-14| 0.0|30.1875|29.6875| 29.875| 0.4985984|2000.0|  DTE|\n",
      "|1962-02-14| 0.0|276.875|273.125| 273.75| 122.42809| 800.0|  NAV|\n",
      "|1962-02-13| 0.0|30.3125| 29.875|  30.25|0.50485736|8400.0|  DTE|\n",
      "|1962-02-13| 0.0|  277.5|  275.0| 276.25| 123.54612|1000.0|  NAV|\n",
      "|1962-02-26| 0.0|29.9375|  29.75|29.9375|0.49964145|2000.0|  DTE|\n",
      "|1962-02-26| 0.0|279.375| 276.25|279.375| 124.94374| 700.0|  NAV|\n",
      "|1962-02-06| 0.0|  28.75|28.5625| 28.625|0.47773674|4400.0|  DTE|\n",
      "|1962-02-06| 0.0|271.875|268.125| 271.25| 121.31004|1600.0|  NAV|\n",
      "|1962-02-02| 0.0|   28.5| 28.375|   28.5| 0.4756507|2200.0|  DTE|\n",
      "|1962-02-02| 0.0| 266.25| 263.75| 266.25|119.073845| 800.0|  NAV|\n",
      "|1962-02-16| 0.0|29.9375|  29.75|  29.75|  0.496513| 800.0|  DTE|\n",
      "|1962-02-16| 0.0|  277.5|274.375|  277.5| 124.10516|1400.0|  NAV|\n",
      "|1962-02-27| 0.0|30.1875| 29.875|   30.0|0.50068444|1600.0|  DTE|\n",
      "|1962-02-27| 0.0|  280.0| 278.75|  280.0|  125.2233| 600.0|  NAV|\n",
      "|1962-02-12| 0.0|  30.25| 29.875|  30.25|0.50485736|3000.0|  DTE|\n",
      "|1962-02-12| 0.0| 276.25|274.375| 276.25| 123.54612| 700.0|  NAV|\n",
      "|1962-02-20| 0.0|29.9375|29.8125|29.8125|0.49755514|1000.0|  DTE|\n",
      "|1962-02-20| 0.0|  280.0|276.875|279.375| 124.94374|1000.0|  NAV|\n",
      "+----------+----+-------+-------+-------+----------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks.where(~F.col('high').between(0.0,mean_high)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-------+-----+\n",
      "|open|   high|    low|  close|stock|\n",
      "+----+-------+-------+-------+-----+\n",
      "| 0.0|29.9375|  29.75|29.9375|  DTE|\n",
      "| 0.0|  280.0|276.875|279.375|  NAV|\n",
      "+----+-------+-------+-------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT open,high,low,close,stock\n",
    "            FROM explore\n",
    "            WHERE low > 17.829749850183724 and close > 17.829749850183724\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+---------+-------+---------+-----------+--------+-----+\n",
      "|      date|open|     high|    low|    close|  adj_close|  volume|stock|\n",
      "+----------+----+---------+-------+---------+-----------+--------+-----+\n",
      "|1962-02-19| 0.0| 3.578869|   20.0| 3.549107|0.056501225|273600.0|  CVX|\n",
      "|1962-02-19| 0.0|  29.9375|  29.75|  29.9375| 0.49964145|  1600.0|  DTE|\n",
      "|1962-02-19| 0.0|    280.0|276.875|  279.375|  124.94374|   600.0|  NAV|\n",
      "|1962-02-14| 0.0|3.4970238|   20.0|3.4970238|0.055672023|116800.0|  CVX|\n",
      "|1962-02-14| 0.0|  30.1875|29.6875|   29.875|  0.4985984|  2000.0|  DTE|\n",
      "|1962-02-14| 0.0|  276.875|273.125|   273.75|  122.42809|   800.0|  NAV|\n",
      "|1962-02-13| 0.0|3.5044644|   20.0|3.5044644|0.055790514|240000.0|  CVX|\n",
      "|1962-02-13| 0.0|  30.3125| 29.875|    30.25| 0.50485736|  8400.0|  DTE|\n",
      "|1962-02-13| 0.0|    277.5|  275.0|   276.25|  123.54612|  1000.0|  NAV|\n",
      "|1962-02-26| 0.0|3.5193453|   20.0| 3.482143|0.055435114|158400.0|  CVX|\n",
      "+----------+----+---------+-------+---------+-----------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks.where(~F.col('low').between(0.0,mean_low)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-------+-----+\n",
      "|open|   high|    low|  close|stock|\n",
      "+----+-------+-------+-------+-----+\n",
      "| 0.0|  280.0|276.875|279.375|  NAV|\n",
      "| 0.0|276.875|273.125| 273.75|  NAV|\n",
      "| 0.0|  277.5|  275.0| 276.25|  NAV|\n",
      "| 0.0|279.375| 276.25|279.375|  NAV|\n",
      "| 0.0|271.875|268.125| 271.25|  NAV|\n",
      "| 0.0| 266.25| 263.75| 266.25|  NAV|\n",
      "| 0.0|  277.5|274.375|  277.5|  NAV|\n",
      "| 0.0|  280.0| 278.75|  280.0|  NAV|\n",
      "| 0.0| 276.25|274.375| 276.25|  NAV|\n",
      "| 0.0|  280.0|276.875|279.375|  NAV|\n",
      "| 0.0|274.375|  272.5| 273.75|  NAV|\n",
      "| 0.0|280.625| 278.75|  280.0|  NAV|\n",
      "| 0.0|  267.5|265.625| 266.25|  NAV|\n",
      "| 0.0|  275.0|271.875| 273.75|  NAV|\n",
      "| 0.0|268.125|265.625| 266.25|  NAV|\n",
      "| 0.0|  275.0|  272.5|274.375|  NAV|\n",
      "| 0.0|274.375|  270.0|274.375|  NAV|\n",
      "| 0.0|279.375| 276.25| 278.75|  NAV|\n",
      "| 0.0| 281.25|276.875|276.875|  NAV|\n",
      "| 0.0|273.125|270.625|273.125|  NAV|\n",
      "+----+-------+-------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT open,high,low,close,stock \n",
    "            FROM explore\n",
    "            WHERE adj_close > 116.5\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-------+-----+\n",
      "|open|   high|    low|  close|stock|\n",
      "+----+-------+-------+-------+-----+\n",
      "| 0.0|29.9375|  29.75|29.9375|  DTE|\n",
      "| 0.0|  280.0|276.875|279.375|  NAV|\n",
      "| 0.0|30.1875|29.6875| 29.875|  DTE|\n",
      "+----+-------+-------+-------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT open,high,low,close,stock \n",
    "            FROM explore\n",
    "            WHERE close > 16.64199179044607\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+-------+-------+----------+------+-----+\n",
      "|      date|open|   high|    low|  close| adj_close|volume|stock|\n",
      "+----------+----+-------+-------+-------+----------+------+-----+\n",
      "|1962-02-19| 0.0|29.9375|  29.75|29.9375|0.49964145|1600.0|  DTE|\n",
      "|1962-02-19| 0.0|  280.0|276.875|279.375| 124.94374| 600.0|  NAV|\n",
      "|1962-02-14| 0.0|30.1875|29.6875| 29.875| 0.4985984|2000.0|  DTE|\n",
      "+----------+----+-------+-------+-------+----------+------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks.where(~F.col('close').between(0.053624976,mean_close)).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-------+-----+\n",
      "|open|   high|    low|  close|stock|\n",
      "+----+-------+-------+-------+-----+\n",
      "| 0.0|  280.0|276.875|279.375|  NAV|\n",
      "| 0.0|276.875|273.125| 273.75|  NAV|\n",
      "| 0.0|  277.5|  275.0| 276.25|  NAV|\n",
      "| 0.0|279.375| 276.25|279.375|  NAV|\n",
      "| 0.0|271.875|268.125| 271.25|  NAV|\n",
      "+----+-------+-------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT open,high,low,close,stock \n",
    "            FROM explore\n",
    "            WHERE adj_close > 5.9866425135353065\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.where(~F.col('adj_close').between(0.000006,mode_adj_close)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----------+----------+----------+------------+---------+-----+\n",
      "|      date|open|      high|       low|     close|   adj_close|   volume|stock|\n",
      "+----------+----+----------+----------+----------+------------+---------+-----+\n",
      "|1962-02-19| 0.0|0.23206018|0.23206018|0.23206018| 6.541049E-7|  43200.0|  JNJ|\n",
      "|1962-02-19| 0.0|     280.0|   276.875|   279.375|   124.94374|    600.0|  NAV|\n",
      "|1962-02-14| 0.0|0.24074075| 0.2337963| 0.2349537| 6.622604E-7|1080000.0|  JNJ|\n",
      "|1962-02-14| 0.0|   276.875|   273.125|    273.75|   122.42809|    800.0|  NAV|\n",
      "|1962-02-13| 0.0|0.24421297|0.24131945|0.24189815|6.8183493E-7| 734400.0|  JNJ|\n",
      "+----------+----+----------+----------+----------+------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks.where(~F.col('adj_close').between(0.000006,mode_adj_close)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 📔️**Notes** 📔️\n",
    "\n",
    " *Use this cell to note down any potential findings.*\n",
    " \n",
    " ### High\n",
    "\n",
    " 1. The DTE and NAV stocks appear to be way outside of the normal bounds, these may be artificially inflated and colud skew the analysis later on. The NAV stock is looking very fishy here, with highs of over $200.00. DTEis playing around hthe high 20's and low 30's. maybe this is acceptable?\n",
    " 2. The mode seems like a good measure for these reding,  since its causing the right skew, and from checking out the modes of all these stocks it looks like \n",
    " \n",
    "### Low\n",
    "\n",
    "1. It appears the same two columns fall outside of the low parameters (min and mean)with the adddtion of the CVX stock\n",
    "\n",
    "### Close \n",
    "\n",
    "1. Again here we have tyhe same the same stocks falling out of the normal ranges. DTE NAV\n",
    "\n",
    "### Adj_close\n",
    "\n",
    "1. It looks like only the NAV stock falls outside of the normal bounds here. this stack may definately need to be removed for a clearer picture of the stocks here. The JNJ stock also falls outside of the mode/mean parameters, this could also be one to watch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Completeness\n",
    "\n",
    "Completeness is the proportion of stored data against the potential of “100% complete\". This is the degree to which the required data is in the dataset. \n",
    "\n",
    "Does the dataset have missing values, or if it is time-series data, does it have time period gaps? Has a bias been introduced that may change your assumptions or affect your results?\n",
    "\n",
    "Completeness issues can occur at the row level (gaps within the dataset) or the field level (one entry missing). At the field level, entire fields can being empty, or >80% of a field's data missing. \n",
    "\n",
    "Another issue that may occur is default values. A typical example of this is where a logger sends back a 0 instead of a null value, which can greatly skew any attempts at modelling. This is where it is instrumental to employ domain knowledge when assessing a dataset. \n",
    "\n",
    "- **Measured by**: A measure of the absence of blank (null) values or the presence of non-blank values;\n",
    "- **Units**: Percentage;\n",
    "- **Related to**: Validity and Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Write code to identify and count the number of missing values (nulls) in the dataset. Include a percentage to describe the proportion of missing values per column. Output the results in the following manner:\n",
    ">\n",
    "> `There are <number_of_missing_values> (<percentage>) null values in <column_name> column`\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 (0.0%) null values in date column\n",
      "There are 0 (0.0%) null values in open column\n",
      "There are 0 (0.0%) null values in high column\n",
      "There are 42 (0.823%) null values in low column\n",
      "There are 0 (0.0%) null values in close column\n",
      "There are 21 (0.411%) null values in adj_close column\n",
      "There are 21 (0.411%) null values in volume column\n",
      "There are 0 (0.0%) null values in stock column\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "missing_count = {}  # Dictionary to keep track of the results\n",
    "for column in stocks.columns:   # loop through each column\n",
    "    _count = stocks.where(stocks[column].isNull()).count()  # null count in column x\n",
    "    _total_count = stocks.select(stocks[column]).count()    # total count of column x \n",
    "    print(f'There are {_count} ({round(_count/_total_count*100, 3)}%) null values in {column} column')  # print out and calculate results\n",
    "    missing_count[f'{column}'] = _count # recording results in missing_count dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> From the above result, probe the columns that are affected by the missing data to find out which stocks were affected.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+----+---------+----------+--------+-----+\n",
      "|      date|     open|     high| low|    close| adj_close|  volume|stock|\n",
      "+----------+---------+---------+----+---------+----------+--------+-----+\n",
      "|1962-12-03|      0.0|    247.5|null|    247.5|  114.7004|   500.0|  NAV|\n",
      "|1962-12-20|      0.0|   241.25|null|  239.375|112.296135|   600.0|  NAV|\n",
      "|1962-12-21|      0.0|  243.125|null|    242.5| 113.76213|   500.0|  NAV|\n",
      "|1962-03-20|1.6666666|1.6979166|null|1.6979166|0.14584826|177600.0|  CAT|\n",
      "|1962-03-14|1.6302084|1.6614584|null|1.6614584|0.14271663|117600.0|  CAT|\n",
      "|1962-12-31|      0.0|  250.625|null|   248.75| 116.69414|   600.0|  NAV|\n",
      "|1962-12-28|      0.0|  249.375|null|  248.125| 116.40094|   300.0|  NAV|\n",
      "|1962-03-22|1.6666666|1.6927084|null|1.6822916|0.14450607|268800.0|  CAT|\n",
      "|1962-12-18|      0.0|   238.75|null|   236.25|  110.8301|   900.0|  NAV|\n",
      "|1962-03-19|1.6614584|1.6822916|null|1.6614584|0.14271663|105600.0|  CAT|\n",
      "|1962-12-19|      0.0|    240.0|null|    240.0|112.589325|   700.0|  NAV|\n",
      "|1962-12-27|      0.0|  248.125|null|  248.125| 116.40094|   600.0|  NAV|\n",
      "|1962-03-15|1.6614584|1.6614584|null|1.6458334|0.14137442|139200.0|  CAT|\n",
      "|1962-03-13|1.6145834|1.6354166|null|    1.625|0.13958487|141600.0|  CAT|\n",
      "|1962-03-01|1.6822916| 1.703125|null|1.6822916|0.14450607| 74400.0|  CAT|\n",
      "|1962-03-27| 1.671875|1.6770834|null| 1.671875|0.14361136|112800.0|  CAT|\n",
      "|1962-12-24|      0.0|    245.0|null|  244.375| 114.64173|   500.0|  NAV|\n",
      "|1962-03-16|1.6458334|1.6614584|null|1.6614584|0.14271663| 79200.0|  CAT|\n",
      "|1962-03-30|1.6822916| 1.703125|null| 1.703125|0.14629564| 86400.0|  CAT|\n",
      "|1962-12-26|      0.0|  246.875|null|   246.25|115.521324|   500.0|  NAV|\n",
      "|1962-03-07|1.6770834|1.6770834|null|  1.65625| 0.1422691|172800.0|  CAT|\n",
      "|1962-03-23|1.6822916|1.6979166|null|1.6822916|0.14450607|189600.0|  CAT|\n",
      "|1962-03-12|1.6354166| 1.640625|null|1.6145834|0.13869008| 96000.0|  CAT|\n",
      "|1962-03-21|1.6979166| 1.703125|null|  1.65625| 0.1422691|232800.0|  CAT|\n",
      "|1962-03-02|1.6822916|   1.6875|null|   1.6875|0.14495347|105600.0|  CAT|\n",
      "|1962-03-08|  1.65625|1.6614584|null| 1.640625|  0.140927| 98400.0|  CAT|\n",
      "|1962-03-29| 1.703125| 1.703125|null|1.6822916|0.14450607| 91200.0|  CAT|\n",
      "|1962-03-28| 1.671875| 1.703125|null| 1.703125|0.14629564|146400.0|  CAT|\n",
      "|1962-03-09| 1.640625|1.6458334|null|1.6354166|0.14047968| 86400.0|  CAT|\n",
      "|1962-03-06|   1.6875| 1.703125|null|1.6770834| 0.1440587| 98400.0|  CAT|\n",
      "|1962-03-26|1.6822916|   1.6875|null| 1.671875|0.14361136|124800.0|  CAT|\n",
      "|1962-03-05|   1.6875|1.6927084|null|   1.6875|0.14495347| 79200.0|  CAT|\n",
      "|1962-12-10|      0.0|  249.375|null|    247.5|  114.7004|  2200.0|  NAV|\n",
      "|1962-12-11|      0.0|  244.375|null|  244.375| 114.64173|   400.0|  NAV|\n",
      "|1962-12-04|      0.0|  249.375|null|  249.375| 115.56933|   500.0|  NAV|\n",
      "|1962-12-17|      0.0|  240.625|null|   238.75| 112.00292|   700.0|  NAV|\n",
      "|1962-12-05|      0.0|   248.75|null|   248.75|115.279655|   500.0|  NAV|\n",
      "|1962-12-14|      0.0|  239.375|null|  239.375|112.296135|   400.0|  NAV|\n",
      "|1962-12-12|      0.0|  244.375|null|   241.25| 113.17572|   600.0|  NAV|\n",
      "|1962-12-13|      0.0|   241.25|null|  238.125| 111.70971|   500.0|  NAV|\n",
      "|1962-12-06|      0.0|  249.375|null|  249.375| 115.56933|   500.0|  NAV|\n",
      "|1962-12-07|      0.0|  251.875|null|    250.0| 115.85895|  1400.0|  NAV|\n",
      "+----------+---------+---------+----+---------+----------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "stocks.filter(\"low is NULL\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above it looks like it's only the NAV (Navient) and CAT (Caterpillar) stocks that have missing data. What's a little strange here is the for the NAV stock all the null low values occur when the open value is zero. The CAT stocks missing low data looks random,maybe it would be best to remove this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix Completeness\n",
    "\n",
    "How do we deal with incomplete data?\n",
    "- Dropping missing values\n",
    "- Discard the incomplete column\n",
    "- Discard the rows containing missing data\n",
    "- Case deletion\n",
    "\n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Use the appropriate strategy to remedy the missing data. \n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Write your code here\n",
    "\n",
    "stocks_clean_low = stocks.na.drop(subset=[\"low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+---+-----+---------+------+-----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|\n",
      "+----+----+----+---+-----+---------+------+-----+\n",
      "+----+----+----+---+-----+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks_clean_low.filter(\"low is NULL\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. The dataframe no longer has missing data for the entire low column and we can move on now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Values\n",
    "\n",
    "Take a deeper look into the entries with many zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix Completeness\n",
    "\n",
    "Completeness issues can be fixed through imputation of the missing data through:\n",
    "- imputation by mean/mode/median;\n",
    "- regression; or\n",
    "- KNN.\n",
    " \n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Write code to identify and count the number of zeros (0) in the dataset. Include a percentage to describe the proportion of missing values per column. Output the results in the following manner:\n",
    ">\n",
    "> `There are <number_of_zeros> (<percentage>) zero values in <column_name> column`\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Write your code here\n",
    "st = stocks_clean_low['open','high','low','close','adj_close','volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2748 (54.265%) zero values in open column\n",
      "There are 20 (0.395%) zero values in high column\n",
      "There are 0 (0.0%) zero values in low column\n",
      "There are 0 (0.0%) zero values in close column\n",
      "There are 0 (0.0%) zero values in adj_close column\n",
      "There are 27 (0.533%) zero values in volume column\n"
     ]
    }
   ],
   "source": [
    "zero_count = {}  # Dictionary to keep track of the results\n",
    "for column in st.columns:   # loop through each column\n",
    "    _count = st.filter(stocks_clean_low[column] == 0).count()  # null count in column x\n",
    "    _total_count = st.select(stocks[column]).count()    # total count of column x \n",
    "    print(f'There are {_count} ({round(_count/_total_count*100, 3)}%) zero values in {column} column')  # print out and calculate results\n",
    "    zero_count[f'{column}'] = _count # recording results in missing_count dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above section, you find that there are a few columns that contain zero values. However, some of these are true zeros and are explainable. Your task is to distinguish which column should undergo data imputation.\n",
    "\n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Investigate the columns with zero values and determine which one should undergo data imputation. Take note of the stock and month on which zero values occurred.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I realise that I need to think about this very carefully. Looking at the open column, It could be fair to think that this coulmn doesn't reeally require any data impuation, so for now I'll leave it as is. The High column However should (instinctively) have some sort of value in in especially of there was volume traded for a prticular stock. The same should be true for the volums column, if a stock has an opening and a closing value, it should have volume traded right? Right, now let's look into this carefully "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+---------+---------+----------+--------+-----+\n",
      "|      date|     open|high|      low|    close| adj_close|  volume|stock|\n",
      "+----------+---------+----+---------+---------+----------+--------+-----+\n",
      "|1962-11-05|1.4114584| 0.0|1.4114584|   1.4375|0.12620474|172800.0|  CAT|\n",
      "|1962-11-12| 1.453125| 0.0|1.4427084|1.4583334|0.12803373| 96000.0|  CAT|\n",
      "+----------+---------+----+---------+---------+----------+--------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "stocks_clean_low.createOrReplaceTempView('st')\n",
    "spark.sql(\"\"\"SELECT * \n",
    "        FROM st\n",
    "        WHERE high = 0\n",
    "        \"\"\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+------------+------+-----+\n",
      "|      date|      open|      high|       low|     close|   adj_close|volume|stock|\n",
      "+----------+----------+----------+----------+----------+------------+------+-----+\n",
      "|1962-05-18|       0.0| 1.6679688| 1.6484375| 1.6679688| 0.015032374|   0.0|  XOM|\n",
      "|1962-05-24|       0.0| 1.6328125| 1.6171875| 1.6289062|  0.01468032|   0.0|  XOM|\n",
      "|1962-09-28|       0.0|0.15914352| 0.1574074|0.15914352| 4.514184E-7|   0.0|  JNJ|\n",
      "|1962-05-08|       0.0| 1.7265625| 1.7109375| 1.7148438| 0.015285846|   0.0|  XOM|\n",
      "|1962-01-02|       0.0|0.22337963|0.22222222|0.22337963| 6.281419E-7|   0.0|  JNJ|\n",
      "|1962-05-14|       0.0|  1.640625| 1.5820312| 1.6328125| 0.014715531|   0.0|  XOM|\n",
      "|1962-05-28|       0.0|    1.5625| 1.4179688|    1.4375| 0.012955305|   0.0|  XOM|\n",
      "|1962-05-25|       0.0| 1.6328125|  1.578125|   1.59375|  0.01436349|   0.0|  XOM|\n",
      "|1962-05-29|       0.0|   1.59375| 1.4179688| 1.5898438| 0.014328282|   0.0|  XOM|\n",
      "|1962-05-02|       0.0| 1.7148438| 1.6992188| 1.7148438| 0.015285846|   0.0|  XOM|\n",
      "|1962-05-31|       0.0| 1.6328125|  1.609375|     1.625| 0.014645126|   0.0|  XOM|\n",
      "|1962-05-16|       0.0| 1.6953125|  1.671875| 1.6796875|0.0151379965|   0.0|  XOM|\n",
      "|1962-05-07|       0.0| 1.7148438| 1.7070312| 1.7148438| 0.015285846|   0.0|  XOM|\n",
      "|1962-05-10|       0.0|    1.6875| 1.6640625| 1.6679688| 0.015032374|   0.0|  XOM|\n",
      "|1962-05-15|       0.0| 1.6914062| 1.6445312| 1.6796875|0.0151379965|   0.0|  XOM|\n",
      "|1962-05-01|       0.0| 1.6992188| 1.6601562| 1.6992188| 0.015146574|   0.0|  XOM|\n",
      "|1962-05-11|       0.0|  1.671875| 1.6445312| 1.6445312| 0.014821144|   0.0|  XOM|\n",
      "|1962-05-17|       0.0| 1.6796875| 1.6484375| 1.6640625|  0.01499716|   0.0|  XOM|\n",
      "|1962-05-21|       0.0|   1.65625| 1.6445312|   1.65625| 0.014926753|   0.0|  XOM|\n",
      "|1962-05-23|       0.0| 1.6367188| 1.6171875| 1.6210938| 0.014609924|   0.0|  XOM|\n",
      "|1962-10-15|       0.0|0.15856482|0.15856482|0.15856482|4.4977733E-7|   0.0|  JNJ|\n",
      "|1962-05-09|       0.0| 1.6953125| 1.6796875|    1.6875| 0.015208395|   0.0|  XOM|\n",
      "|1962-05-04|       0.0| 1.7226562| 1.7109375|   1.71875|0.0153206745|   0.0|  XOM|\n",
      "|1962-05-03|       0.0| 1.7304688| 1.7148438|   1.71875|0.0153206745|   0.0|  XOM|\n",
      "|1962-05-22|       0.0| 1.6601562| 1.6289062|  1.640625| 0.014785934|   0.0|  XOM|\n",
      "|1962-11-09|0.69736576|0.69736576|0.69736576|0.69736576|0.0016955283|   0.0|   GE|\n",
      "|1962-04-17|       0.0|   0.21875| 0.2175926|   0.21875|6.1658733E-7|   0.0|  JNJ|\n",
      "+----------+----------+----------+----------+----------+------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * \n",
    "        FROM st\n",
    "        WHERE volume = 0\n",
    "        \"\"\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the only culprit here is the CAT stock and it's reaponsible for all 20 missing high values. looking at it a little more closely though, this shouldn't be the case for instances where the closing value is higher than the open value.  according to the below instructios this is the cloumn that will have to be given the average value of the stock.\n",
    "\n",
    "The XOM and JNJ stocks have missing values in the volume column, which to me dosen't make sence since there was tradeing for these stocks on the days the volume was zero. The GE stock also has missing volume data for 1962-11-09, but this looks legit-ish, so I'll leave it as is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Once you have identified the column that needs to undergo imputation, update the values for the affected records by using the average value for the affected stock.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_window = Window.partitionBy(F.col('stock'))\n",
    "\n",
    "df_months_imputed = df_months.withColumn('high', F.when(F.col('high') =0, F.mean('high').over(cat_window)).otherwise(F.col('high')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+---+-----+---------+------+-----+-----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_months_imputed.createOrReplaceTempView('see2')\n",
    "spark.sql(\"\"\"select * from see2 where high = 0\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_months_imputed2 = df_months_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+---+-----+---------+------+-----+-----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_months_imputed2 = df_months_imputed.withColumn('volume', F.when(F.col('volume') ==0, F.mean('volume').over(cat_window)).otherwise(F.col('volume')))\n",
    "df_months_imputed2.createOrReplaceTempView('see3')\n",
    "spark.sql(\"\"\"select * from see3 where volume= 0\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks legit. I can say with certanty that the data has been successfully imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Consistency\n",
    "\n",
    "Consistency is the absence of difference when comparing two or more representations of a thing against a reference.\n",
    "\n",
    "Data entries that refer to the same record or entity have to be consistent across all entries, e.g., if you are dealing with records from a logger in the field, the entries for that logger have to remain consistent, and the name or primary key of that logger cannot change from one entry to another. \n",
    "\n",
    "For example, 'Logger1', 'Loger1' and 'Logge1' are examples of inconsistent keys. \n",
    "\n",
    "This is not just within a single table but also becomes more important if you are dealing with relational data. In which case, the mappings between tables and systems must be consistent. If not, the relationships will be completely lost between the tables and referential integrity compromised. \n",
    "\n",
    "- **Measured by**: Analysis of pattern and/or value frequency;\n",
    "- **Units**: Percentage;\n",
    "- **Related to**: Accuracy, Validity, and Uniqueness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> There currently exists a stock that has inconsistent naming. Make use of the metadata to determine which stock is inconsistently named, then update the dataframe appropriately to get rid of this inconsistency.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata.select(F.col(\"symbol\")).show(5000)\n",
    "symbol_list = list(metadata.select('symbol').toPandas()['symbol'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Write your code here\n",
    "# df_months_imputed2.select(F.col(\"stock\")).orderBy(F.col(\"stock\")).show(5000)\n",
    "stock_list = list(df_months_imputed2.select('stock').toPandas()['stock'])\n",
    "stock_list = list(dict.fromkeys(stock_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock ARNCA isn't in the metadata list\n"
     ]
    }
   ],
   "source": [
    "for stock in stock_list:\n",
    "        \n",
    "    if stock in symbol_list:\n",
    "        continue \n",
    "    else:\n",
    "        print(\"stock \"+ stock+\" isn't in the metadata list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistant_df = df_months_imputed2.withColumn(\"stock\", F.when(df_months_imputed2.stock == \"ARNCA\",\"ARNC\") \\\n",
    "      .otherwise(df_months_imputed2.stock))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeliness\n",
    "\n",
    "Timeliness is the degree to which data represent reality from the required point in time.\n",
    "\n",
    "Timeliness expects that the data within your dataset is sufficiently up to date. If you are trying to answer questions that relate to recent problems, having timely data is extremely important. For example, you cannot use current flight patterns to model how many aeroplanes will be required by a large aeronautics company within the next 5-10 years. \n",
    "\n",
    "Similarly, when answering questions that require real-time answers (e.g., predicting when a pipe will burst in a manufacturing plant), you have to be set up to receive real-time data from sensors and loggers. \n",
    "\n",
    "- **Measured by**: Time difference;\n",
    "- **Units**: Time;\n",
    "- **Related to**: Accuracy because it will decay as time progress. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to see the latest value for each of the stocks that we are looking at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|stock| max(Date)|\n",
      "+-----+----------+\n",
      "|   AA|1962-12-31|\n",
      "|   BA|1962-12-31|\n",
      "|   ED|1962-12-31|\n",
      "|   FL|1962-12-31|\n",
      "|  IBM|1962-12-31|\n",
      "|   GE|1962-12-31|\n",
      "| ARNC|1962-12-31|\n",
      "|  CVX|1962-12-31|\n",
      "|  NAV|1962-11-30|\n",
      "|   PG|1962-12-31|\n",
      "|  DIS|1962-12-31|\n",
      "|  HPQ|1962-12-31|\n",
      "|   IP|1962-12-31|\n",
      "|   KO|1962-12-31|\n",
      "|   MO|1962-12-31|\n",
      "|  XOM|1962-12-31|\n",
      "|  CAT|1962-12-31|\n",
      "|  DTE|1962-12-31|\n",
      "|   GT|1962-12-31|\n",
      "|  JNJ|1962-12-31|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consistant_df.groupBy('stock').agg(F.max('Date')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, some of these axes of data quality will be less important than others. \n",
    "This is one of those cases where it is less important to have timely data, since \n",
    "we are trying to create a training dataset for a stock market prediction algorithm. \n",
    "\n",
    "It is important to know the context in which you are doing your modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaps in the dataset\n",
    "\n",
    "Let's see if we can find inconsistencies in the time series by having a look at the number of entries for each of the tickers.\n",
    " \n",
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Uncomment and use the below code to determine which dates had entries that were not equal to 20. You may have to change the name of the dataframe to see the resultant output\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|count|\n",
      "+----------+-----+\n",
      "|1962-02-19|   23|\n",
      "|1962-02-05|   23|\n",
      "|1962-02-01|   23|\n",
      "|1962-02-07|   23|\n",
      "|1962-09-25|   21|\n",
      "|1962-09-24|   21|\n",
      "|1962-03-22|   19|\n",
      "|1962-02-27|   23|\n",
      "|1962-09-12|   21|\n",
      "|1962-09-10|   21|\n",
      "|1962-09-13|   21|\n",
      "|1962-12-03|   19|\n",
      "|1962-02-06|   23|\n",
      "|1962-02-02|   23|\n",
      "|1962-02-12|   23|\n",
      "|1962-02-09|   23|\n",
      "|1962-02-15|   23|\n",
      "|1962-09-26|   21|\n",
      "|1962-09-04|   21|\n",
      "|1962-09-17|   21|\n",
      "|1962-09-21|   21|\n",
      "|1962-09-28|   21|\n",
      "|1962-03-20|   19|\n",
      "|1962-12-31|   19|\n",
      "|1962-12-28|   19|\n",
      "|1962-03-19|   19|\n",
      "|1962-02-14|   23|\n",
      "|1962-02-28|   23|\n",
      "|1962-02-23|   23|\n",
      "|1962-09-07|   21|\n",
      "|1962-09-11|   21|\n",
      "|1962-09-05|   21|\n",
      "|1962-09-14|   21|\n",
      "|1962-09-27|   21|\n",
      "|1962-12-21|   19|\n",
      "|1962-03-14|   19|\n",
      "|1962-12-18|   19|\n",
      "|1962-02-13|   23|\n",
      "|1962-02-26|   23|\n",
      "|1962-02-16|   23|\n",
      "|1962-02-20|   23|\n",
      "|1962-02-08|   23|\n",
      "|1962-02-21|   23|\n",
      "|1962-09-18|   21|\n",
      "|1962-09-20|   21|\n",
      "|1962-09-06|   21|\n",
      "|1962-09-19|   21|\n",
      "|1962-12-20|   19|\n",
      "|1962-12-26|   19|\n",
      "|1962-12-19|   19|\n",
      "|1962-03-13|   19|\n",
      "|1962-12-24|   19|\n",
      "|1962-03-30|   19|\n",
      "|1962-03-29|   19|\n",
      "|1962-03-26|   19|\n",
      "|1962-12-10|   18|\n",
      "|1962-12-11|   18|\n",
      "|1962-12-13|   18|\n",
      "|1962-03-15|   19|\n",
      "|1962-03-23|   19|\n",
      "|1962-03-06|   19|\n",
      "|1962-12-04|   18|\n",
      "|1962-12-14|   18|\n",
      "|1962-12-12|   18|\n",
      "|1962-12-07|   18|\n",
      "|1962-03-27|   19|\n",
      "|1962-03-16|   19|\n",
      "|1962-03-12|   19|\n",
      "|1962-03-02|   19|\n",
      "|1962-03-08|   19|\n",
      "|1962-03-05|   19|\n",
      "|1962-12-17|   18|\n",
      "|1962-12-27|   19|\n",
      "|1962-03-01|   19|\n",
      "|1962-03-07|   19|\n",
      "|1962-03-21|   19|\n",
      "|1962-03-28|   19|\n",
      "|1962-03-09|   19|\n",
      "|1962-12-05|   18|\n",
      "|1962-12-06|   18|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consistant_df.orderBy('date').groupby('date').count().where(F.col('count') != 20).show(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> From the above result, investigate the number of times a stock appears for the given month. You can infer the months by using the output of the previous cell.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----------------+--------+-------+---------+-------+-----+-----+\n",
      "|      date|   open|             high|     low|  close|adj_close| volume|stock|month|\n",
      "+----------+-------+-----------------+--------+-------+---------+-------+-----+-----+\n",
      "|1962-02-19|5.83929|5.907374858856201| 5.83929|5.86332|1.3863293|29900.0|   AA|    2|\n",
      "|1962-02-14|5.83929|5.839290142059326|5.747175|5.80725|1.3730713|56500.0|   AA|    2|\n",
      "+----------+-------+-----------------+--------+-------+---------+-------+-----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "consistant_df.show(2)\n",
    "# consistant_df.groupby(['month'])['stock'].value_counts().unstack().fillna(0).astype(int).reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|month|stock|count|\n",
      "+-----+-----+-----+\n",
      "|    1|   MO|   22|\n",
      "|    1| ARNC|   22|\n",
      "|    1|   BA|   22|\n",
      "+-----+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consistant_df.groupBy(\"month\",\"stock\").count().orderBy('month').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniqueness\n",
    "\n",
    "Uniqueness requires that nothing will be recorded more than once based upon how that thing is identified. It is the inverse of an assessment of the level of duplication.\n",
    "\n",
    "Each entry within the dataset should only relate to a single event that has occurred and thus should not be duplicated. This is largely mediated by having the appropriate primary key, which means sticking to the requirements of a good primary key. All fields in the tables should be non-transitively dependent on the primary key.\n",
    "\n",
    "As such, deduplication of the dataset may be required. \n",
    "\n",
    "- **Measured by**: Analysis of the number of things assessed in the “real world” compared to the number of records of things in the dataset. This requires a reference dataset which is the ground truth;\n",
    "- **Units**: Percentage;\n",
    "- **Related to**: Consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplication Test\n",
    "For time-series data, it is important to check for duplications, as we typically expect all values to be unique within the dataset.\n",
    "\n",
    "The first thing to check will be if the primary key values within the dataset are unique - in our case, that will be a combination of the stock name and the date.\n",
    "\n",
    "Secondly, we want to check if the entries are all unique, which is done by checking for duplicates across that whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Write code to determine if there are any duplicates within the data, and then proceed to correct this by dropping them from the dataframe.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|      date|stock|count|\n",
      "+----------+-----+-----+\n",
      "|1962-02-06|  HPQ|    4|\n",
      "|1962-02-13|  HPQ|    4|\n",
      "|1962-02-02|  HPQ|    4|\n",
      "|1962-02-15|  HPQ|    4|\n",
      "|1962-02-27|  HPQ|    4|\n",
      "|1962-02-16|  HPQ|    4|\n",
      "|1962-02-26|  HPQ|    4|\n",
      "|1962-02-09|  HPQ|    4|\n",
      "|1962-02-12|  HPQ|    4|\n",
      "|1962-02-07|  HPQ|    4|\n",
      "|1962-02-21|  HPQ|    4|\n",
      "|1962-02-20|  HPQ|    4|\n",
      "|1962-02-19|  HPQ|    4|\n",
      "|1962-02-01|  HPQ|    4|\n",
      "|1962-02-28|  HPQ|    4|\n",
      "|1962-02-23|  HPQ|    4|\n",
      "|1962-02-14|  HPQ|    4|\n",
      "|1962-02-08|  HPQ|    4|\n",
      "|1962-02-05|  HPQ|    4|\n",
      "|1962-09-13|   ED|    2|\n",
      "|1962-09-06|   ED|    2|\n",
      "|1962-09-14|   ED|    2|\n",
      "|1962-09-18|   ED|    2|\n",
      "|1962-09-26|   ED|    2|\n",
      "|1962-09-21|   ED|    2|\n",
      "|1962-09-25|   ED|    2|\n",
      "|1962-09-20|   ED|    2|\n",
      "|1962-09-17|   ED|    2|\n",
      "|1962-09-04|   ED|    2|\n",
      "|1962-09-28|   ED|    2|\n",
      "|1962-09-07|   ED|    2|\n",
      "|1962-09-24|   ED|    2|\n",
      "|1962-09-19|   ED|    2|\n",
      "|1962-09-12|   ED|    2|\n",
      "|1962-09-10|   ED|    2|\n",
      "|1962-09-27|   ED|    2|\n",
      "|1962-09-05|   ED|    2|\n",
      "|1962-09-11|   ED|    2|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "\n",
    "consistant_df.groupby(['date', 'stock']) \\\n",
    "  .count() \\\n",
    "  .where('count > 1') \\\n",
    "  .sort('count', ascending=False) \\\n",
    "  .show(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at duplicates, it seems we have quite high number of dulicates for the HP stock(HPQ)and the ED stock on various dates, this will most certsinly need to be rectified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicates = consistant_df.dropDuplicates(['date', 'stock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------------------+--------+--------+---------+-------+-----+-----+\n",
      "|      date|   open|              high|     low|   close|adj_close| volume|stock|month|\n",
      "+----------+-------+------------------+--------+--------+---------+-------+-----+-----+\n",
      "|1962-02-14|5.83929| 5.839290142059326|5.747175| 5.80725|1.3730713|56500.0|   AA|    2|\n",
      "|1962-02-13|5.85531| 5.915384769439697| 5.85531| 5.86332|1.3863293|62500.0|   AA|    2|\n",
      "|1962-02-26|6.05556|6.1076250076293945|5.955435|6.107625|1.4440926|82500.0|   AA|    2|\n",
      "+----------+-------+------------------+--------+--------+---------+-------+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_duplicates.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|date|stock|count|\n",
      "+----+-----+-----+\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_duplicates.groupby(['date', 'stock']) \\\n",
    "  .count() \\\n",
    "  .where('count > 1') \\\n",
    "  .sort('count', ascending=False) \\\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validity\n",
    "Data is valid if it conforms to the syntax (format, type, range) of its definition.\n",
    "\n",
    "Certain values within a field may have specific criteria required to make it valid, e.g., numerical columns cannot contain alphabetical characters, which can occur due to scientific notation.\n",
    "\n",
    "This can be more difficult to determine in stings, in which case you may have to check using regex. \n",
    "\n",
    "- **Measured by**: Comparison between the data and metadata or documentation for the data item;\n",
    "- **Units**: Percentage of data items deemed Valid or Invalid;\n",
    "- **Related to**: Accuracy, Completeness, Consistency, and Uniqueness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to first define what we expect from our dataset:\n",
    "\n",
    "- stock: string (nullable = true) => Should be contained in the list of expected tickers\n",
    "- date: date (nullable = true) => Should conform to date format, and be in the past\n",
    "- open: double (nullable = true) => Should be positive or 0\n",
    "- high: double (nullable = true) => Should be positive or 0\n",
    "- low: double (nullable = true) => Should be positive or 0 (should be < high)\n",
    "- close: double (nullable = true) => Should be positive or 0 (should be <= high )\n",
    "- adj_close: double (nullable = true) => Should be positive or 0\n",
    "- volume: integer (nullable = true) => Should be positive or 0\n",
    "- high_avg: double (nullable = true) => Derived (not needed to test)\n",
    "- high_imp: double (nullable = true) => Derived (not needed to test)\n",
    "- day_of_week: string (nullable = true) => Derived (not needed to test)\n",
    "\n",
    "*Is there any other logic that we can incorporate?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    "> Use the metadata to check if all the stocks in your current dataframe are valid. In other words, make sure you have no foreign/unknown tickers in your dataframe.\n",
    ">\n",
    ">*You may use as many coding cells as necessary.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock AA is in the metadata list\n",
      "stock IBM is in the metadata list\n",
      "stock JNJ is in the metadata list\n",
      "stock KO is in the metadata list\n",
      "stock PG is in the metadata list\n",
      "stock ARNC is in the metadata list\n",
      "stock FL is in the metadata list\n",
      "stock IP is in the metadata list\n",
      "stock CAT is in the metadata list\n",
      "stock CVX is in the metadata list\n",
      "stock HPQ is in the metadata list\n",
      "stock XOM is in the metadata list\n",
      "stock BA is in the metadata list\n",
      "stock DTE is in the metadata list\n",
      "stock GT is in the metadata list\n",
      "stock GE is in the metadata list\n",
      "stock DIS is in the metadata list\n",
      "stock NAV is in the metadata list\n",
      "stock ED is in the metadata list\n",
      "stock MO is in the metadata list\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "stock_list = list(no_duplicates.select('stock').toPandas()['stock'])\n",
    "stock_list = list(dict.fromkeys(stock_list))\n",
    "\n",
    "for stock in stock_list:  \n",
    "    if stock in symbol_list:\n",
    "        print(\"stock \"+ stock+\" is in the metadata list\") \n",
    "    else:\n",
    "        print(\"stock \"+ stock+\" isn't in the metadata list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like all the tickers in the dataframe are correct - we can proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    ">\n",
    ">Check if the date column contains only valid dates and all dates are in the past.\n",
    ">\n",
    ">*Valid dates should already be checked in the data reading step.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|year|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "no_duplicates_year = no_duplicates.withColumn(\"year\", F.year('date'))\n",
    "no_duplicates_year.createOrReplaceTempView('inspect')\n",
    "\n",
    "spark.sql(\"\"\"SELECT * FROM inspect where year != 1962\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the years are all consistant, none in the past and none in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ **Instructions** ℹ️\n",
    ">\n",
    ">Check that all of numerical columns are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|year|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|year|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|year|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|year|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|year|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|year|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "|date|open|high|low|close|adj_close|volume|stock|month|year|\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "+----+----+----+---+-----+---------+------+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: Write your code here\n",
    "spark.sql(\"\"\"SELECT * FROM inspect where open < 0\"\"\").show()\n",
    "spark.sql(\"\"\"SELECT * FROM inspect where high < 0 \"\"\").show()\n",
    "spark.sql(\"\"\"SELECT * FROM inspect where low < 0\"\"\").show()\n",
    "spark.sql(\"\"\"SELECT * FROM inspect where close < 0\"\"\").show()\n",
    "spark.sql(\"\"\"SELECT * FROM inspect where adj_close < 0\"\"\").show()\n",
    "spark.sql(\"\"\"SELECT * FROM inspect where volume < 0\"\"\").show()\n",
    "spark.sql(\"\"\"SELECT * FROM inspect where stock < 0\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are no numeric values lower than zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------------+------+------+---------+-------+-----+-----+----+\n",
      "|      date|  open|             high|   low| close|adj_close| volume|stock|month|year|\n",
      "+----------+------+-----------------+------+------+---------+-------+-----+-----+----+\n",
      "|1962-03-15|6.6483|6.724394798278809|6.6483|6.6483|1.5719309|41900.0|   AA|    3|1962|\n",
      "+----------+------+-----------------+------+------+---------+-------+-----+-----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM inspect where month = 03\"\"\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Updates\n",
    "\n",
    "With our initial work of checking the various dimensions of the data quality completed, we can now save these results to a CSV file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = no_duplicates_year.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df.to_csv('/Users/daluxolombatha/Desktop/Daluxolo_Mbatha_data_profiling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24a0a2ddc4dffcb168e507551dd24967ddc40ea2df7a72a200a74e0ae6d88beb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
